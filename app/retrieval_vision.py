"""
Vision RAG branch: Retrieves relevant page images and generates summaries.
Uses the exact approach from single_pdf_colpali_qdrant.ipynb notebook.
"""

from typing import List, Dict, Any
import torch
from PIL import Image

from config import (
    VISION_COLLECTION_NAME,
    VISION_RETRIEVAL_LIMIT,
    MIN_VISION_SCORE,
    VLM_MAX_NEW_TOKENS,
    DEVICE,
)
from models_local import get_colpali_models, get_qwen_vlm_models, get_qdrant_client
from utils import embed_query_colpali, load_and_validate_image


def retrieve_vision_pages(query: str, limit: int = None) -> List[Dict[str, Any]]:
    """
    Retrieve relevant page images from Qdrant based on the user query.
    Then use Qwen VLM to generate summaries of each retrieved page.

    This implements the exact approach from single_pdf_colpali_qdrant.ipynb:
    1. Embed the query using ColPali with mean pooling
    2. Search the 'pdf_pages' collection in Qdrant
    3. For each retrieved page, use Qwen2-VL to generate a summary
    4. Return structured results with summaries and page references

    Args:
        query: User's question/query text
        limit: Maximum number of pages to retrieve (defaults to config setting)

    Returns:
        List of dictionaries with keys:
        - page_image_path: Path to the page image file
        - page_index: 0-based page index
        - pdf_file_name: Source PDF filename
        - summary: Text summary generated by Qwen VLM
        - score: Similarity score from ColPali retrieval

    Raises:
        Exception: If embedding, retrieval, or VLM inference fails
    """
    if limit is None:
        limit = VISION_RETRIEVAL_LIMIT

    try:
        # Step 1: Get models and client
        colpali_model, colpali_processor = get_colpali_models()
        qdrant_client = get_qdrant_client()

        print(f"[VISION RETRIEVAL] Embedding query with ColPali: '{query[:50]}...'")

        # Step 2: Embed query using ColPali with mean pooling (exact notebook method)
        query_vector = embed_query_colpali(
            query,
            colpali_model,
            colpali_processor,
            DEVICE
        )

        print(f"[VISION RETRIEVAL] Query vector dimension: {len(query_vector)}")

        # Step 3: Search Qdrant for similar pages
        search_results = qdrant_client.search(
            collection_name=VISION_COLLECTION_NAME,
            query_vector=query_vector,
            limit=limit,
            with_payload=True,
        )

        print(f"[VISION RETRIEVAL] Found {len(search_results)} pages")

        # Step 4: Filter by minimum score
        filtered_results = [
            r for r in search_results
            if r.score >= MIN_VISION_SCORE
        ]

        print(f"[VISION RETRIEVAL] {len(filtered_results)} pages after score filtering")

        if not filtered_results:
            return []

        # Step 5: Generate summaries using Qwen VLM for each page
        summaries = []
        for idx, result in enumerate(filtered_results):
            page_info = {
                "page_image_path": result.payload.get("image_path", ""),
                "page_index": result.payload.get("page_index", -1),
                "pdf_file_name": result.payload.get("pdf_file_name", "unknown"),
                "score": float(result.score),
            }

            # Generate summary for this page
            try:
                summary_text = _generate_page_summary(
                    query=query,
                    image_path=page_info["page_image_path"],
                )
                page_info["summary"] = summary_text

                print(f"[VISION RETRIEVAL] Generated summary for page {page_info['page_index'] + 1}")

            except Exception as e:
                print(f"[WARNING] Failed to generate summary for page {page_info['page_index'] + 1}: {e}")
                page_info["summary"] = f"[Error generating summary: {str(e)}]"

            summaries.append(page_info)

        print(f"[VISION RETRIEVAL] Returning {len(summaries)} pages with summaries")

        return summaries

    except Exception as e:
        print(f"[ERROR] Vision retrieval failed: {e}")
        raise


def _generate_page_summary(query: str, image_path: str) -> str:
    """
    Generate a summary of a page image using Qwen2-VL.
    This is the exact approach from the notebook's answer_question_with_vlm function.

    Args:
        query: User's question (to focus the summary)
        image_path: Path to the page image

    Returns:
        Generated summary text

    Raises:
        Exception: If VLM inference fails
    """
    try:
        # Load VLM models
        vlm_model, vlm_processor = get_qwen_vlm_models()

        # Load and validate image
        page_image = load_and_validate_image(image_path)

        # Build chat template (exact notebook approach)
        chat_template = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": page_image},
                    {
                        "type": "text",
                        "text": f"Based on this page, {query}"
                    },
                ],
            }
        ]

        # Apply chat template
        text_prompt = vlm_processor.apply_chat_template(
            chat_template,
            tokenize=False,
            add_generation_prompt=True,
        )

        # Process vision info (requires qwen_vl_utils)
        from qwen_vl_utils import process_vision_info
        image_inputs, _ = process_vision_info(chat_template)

        # Prepare inputs for model
        inputs = vlm_processor(
            text=[text_prompt],
            images=image_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

        # Generate summary
        with torch.no_grad():
            generated_ids = vlm_model.generate(
                **inputs,
                max_new_tokens=VLM_MAX_NEW_TOKENS
            )

        # Decode output (trim prompt tokens)
        generated_ids_trimmed = [
            out_ids[len(in_ids):]
            for in_ids, out_ids in zip(inputs["input_ids"], generated_ids)
        ]

        output_text = vlm_processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False,
        )

        return output_text[0].strip()

    except Exception as e:
        print(f"[ERROR] VLM summary generation failed: {e}")
        raise


def check_vision_collection_exists() -> bool:
    """
    Check if the vision collection exists in Qdrant.
    Useful for validation at startup.

    Returns:
        True if collection exists, False otherwise
    """
    try:
        qdrant_client = get_qdrant_client()
        collections = qdrant_client.get_collections()

        collection_names = [c.name for c in collections.collections]
        exists = VISION_COLLECTION_NAME in collection_names

        if exists:
            print(f"[VISION RETRIEVAL] Collection '{VISION_COLLECTION_NAME}' found in Qdrant")
        else:
            print(f"[WARNING] Collection '{VISION_COLLECTION_NAME}' NOT found in Qdrant")
            print(f"[WARNING] Available collections: {collection_names}")

        return exists

    except Exception as e:
        print(f"[ERROR] Failed to check vision collection: {e}")
        return False


def get_vision_collection_info() -> Dict[str, Any]:
    """
    Get information about the vision collection (vector count, config, etc.).
    Useful for debugging and UI display.

    Returns:
        Dictionary with collection information
    """
    try:
        qdrant_client = get_qdrant_client()

        collection_info = qdrant_client.get_collection(VISION_COLLECTION_NAME)

        return {
            "name": VISION_COLLECTION_NAME,
            "vectors_count": collection_info.vectors_count,
            "points_count": collection_info.points_count,
            "status": collection_info.status,
        }

    except Exception as e:
        print(f"[ERROR] Failed to get vision collection info: {e}")
        return {
            "name": VISION_COLLECTION_NAME,
            "error": str(e),
        }


def test_vision_retrieval() -> bool:
    """
    Test vision retrieval with a simple query.
    Useful for health checks and debugging.

    Returns:
        True if retrieval works, False otherwise
    """
    try:
        test_query = "Show me information about the main topic."
        results = retrieve_vision_pages(test_query, limit=1)

        success = len(results) > 0
        if success:
            print(f"[VISION RETRIEVAL TEST] SUCCESS - Retrieved {len(results)} results")
        else:
            print("[VISION RETRIEVAL TEST] WARNING - No results returned")

        return success

    except Exception as e:
        print(f"[VISION RETRIEVAL TEST] FAILED - {e}")
        return False
